{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import threading\n",
    "import subprocess\n",
    "import torch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLUX Youtube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\benfo/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-8-24 Python-3.11.3 torch-2.2.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL du flux m3u8: https://manifest.googlevideo.com/api/manifest/hls_playlist/expire/1724539385/ei/mQ3KZpQ23OTE3w_g2IvQDA/ip/2a01:cb05:4c0:4100:f9ac:ebfb:eefe:bb51/id/AGyccIEcsZ0.1/itag/96/source/yt_live_broadcast/requiressl/yes/ratebypass/yes/live/1/sgoap/gir%3Dyes%3Bitag%3D140/sgovp/gir%3Dyes%3Bitag%3D137/rqh/1/hdlc/1/hls_chunk_host/rr5---sn-25glenlk.googlevideo.com/xpc/EgVo2aDSNQ%3D%3D/spc/Mv1m9sQxoSK_9KQrj-0x3aP8QceCVMYu73_s16GkbBhc30o233wXTTY/vprv/1/playlist_type/DVR/initcwndbps/1627500/mh/xR/mm/44/mn/sn-25glenlk/ms/lva/mv/m/mvi/5/pl/42/dover/11/pacing/0/keepalive/yes/mt/1724517643/sparams/expire,ei,ip,id,itag,source,requiressl,ratebypass,live,sgoap,sgovp,rqh,hdlc,xpc,spc,vprv,playlist_type/sig/AJfQdSswRQIgFsGiEk53n7h_gKz4MGTJij541fJQrv4nvlxRkmeNQo0CIQDeu7FIRPpKQsoRjsCYpCSD62XNvQHIBMhyVmPrg2IErg%3D%3D/lsparams/hls_chunk_host,initcwndbps,mh,mm,mn,ms,mv,mvi,pl/lsig/AGtxev0wRQIhAKQJuN84YiVUPdK1m0YRtO8SFjmzi2LMcSrRhpTbyXhYAiBX0xKyaZ9GKabDYUw_2p7sezMritkvajV_i5tqoXBIPg%3D%3D/playlist/index.m3u8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-19 (update):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benfo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\benfo\\OneDrive\\Bureau\\DjiProject\\code\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"C:\\Users\\benfo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\threading.py\", line 975, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\benfo\\AppData\\Local\\Temp\\ipykernel_12656\\3111369610.py\", line 15, in update\n",
      "cv2.error: Unknown C++ exception from OpenCV code\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, src):\n",
    "        self.cap = cv2.VideoCapture(src)\n",
    "        self.ret, self.frame = self.cap.read()\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        threading.Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        while not self.stopped:\n",
    "            if not self.ret:\n",
    "                self.stop()\n",
    "            self.ret, self.frame = self.cap.read()\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True\n",
    "        self.cap.release()\n",
    "\n",
    "# Charger le modèle YOLO\n",
    "# model = YOLO(\"yolov8n.pt\") #for Yolov8\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5s_best_fire_weights.pt')\n",
    "\n",
    "# Remplacer VIDEO_ID par l'ID de la vidéo YouTube en direct\n",
    "video_url = \"https://www.youtube.com/watch?v=AGyccIEcsZ0\"\n",
    "command = [\"yt-dlp\", \"-g\", video_url]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "    url_m3u8 = result.stdout.strip()\n",
    "\n",
    "    print(\"URL du flux m3u8:\", url_m3u8)\n",
    "\n",
    "    # Démarrer la capture vidéo avec threading\n",
    "    video_stream = VideoStream(url_m3u8).start()\n",
    "\n",
    "    window_width, window_height = 640, 360\n",
    "\n",
    "    while True:\n",
    "        frame = video_stream.read()\n",
    "\n",
    "        if frame is None:\n",
    "            print(\"Erreur : Impossible de lire le flux vidéo\")\n",
    "            break\n",
    "\n",
    "        # Redimensionner la frame pour une meilleure fluidité\n",
    "        frame_resized = cv2.resize(frame, (window_width, window_height))\n",
    "\n",
    "        # Effectuer la détection d'objets sur la frame redimensionnée\n",
    "        results = model(frame_resized)\n",
    "\n",
    "        # for result in results:\n",
    "        #     boxes = result.boxes  # Boîtes de délimitation\n",
    "        #     if boxes is not None:\n",
    "        #         for box in boxes:\n",
    "        #             x1, y1, x2, y2 = box.xyxy[0]  # Coordonnées des coins\n",
    "        #             conf = box.conf[0]  # Confiance\n",
    "        #             if conf >= 0.3:  # Appliquer un seuil de confiance\n",
    "        #                 cls = box.cls[0]  # Classe de l'objet détecté\n",
    "        #                 label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "        #                 cv2.rectangle(frame_resized, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        #                 cv2.putText(frame_resized, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        for pred in results.pred[0]:\n",
    "            x1, y1, x2, y2, conf, cls = pred[:6]\n",
    "            if conf > 0.3:  # Appliquer un seuil de confiance\n",
    "                label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "                cv2.rectangle(frame_resized, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        # Afficher la frame redimensionnée avec les détections\n",
    "        cv2.imshow('Live Stream with YOLOv5 Detection', frame_resized)\n",
    "\n",
    "        # Quitter avec la touche 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video_stream.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Erreur lors de l'exécution de la commande : {e}\")\n",
    "    print(f\"Code de retour : {e.returncode}\")\n",
    "    print(f\"Message d'erreur : {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\benfo/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-8-24 Python-3.11.3 torch-2.2.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "pred\n",
      "Start\n",
      "Start\n",
      "Start\n"
     ]
    }
   ],
   "source": [
    "# Répertoire contenant les images à inférer\n",
    "image_dir = 'Images'  # Remplacez par le chemin de votre dossier d'images\n",
    "\n",
    "# Répertoire de sortie pour les images avec détection (facultatif)\n",
    "output_dir = os.path.expanduser('~/output_images')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5s_best_fire_weights.pt')\n",
    "\n",
    "\n",
    "# Boucle sur toutes les images du répertoire\n",
    "for img_name in os.listdir(image_dir):\n",
    "    # Charger l'image\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Effectuer la détection d'objets\n",
    "    results = model(img)\n",
    "    print(\"Start\")\n",
    "    # Afficher et sauvegarder les résultats\n",
    "    for pred in results.pred[0]:\n",
    "        print(\"pred\")\n",
    "    \n",
    "        x1, y1, x2, y2, conf, cls = pred[:6]\n",
    "       \n",
    "        label = f\"{model.names[int(cls)]}: {conf:.2f}\"\n",
    "        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    # # Sauvegarder l'image avec les détections\n",
    "    output_img_path = os.path.join(output_dir, img_name)\n",
    "    cv2.imwrite(output_img_path, img)\n",
    "\n",
    "    # Quitter avec la touche 'q'\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Fermer toutes les fenêtres\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
